{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ion-ian/MachineLearning_Code/blob/master/Neural_Netwrok_1_FER2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1YPRIpz4Y3s",
        "outputId": "d2750dd7-55f7-47e6-bf4c-a2e9d619a89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T4 GPU Enabled\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"T4 GPU Enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error enabling memory growth: {e}\")\n",
        "else:\n",
        "    print(\"No GPUs available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkLPhBUh4Y3z",
        "outputId": "40f388db-31e1-4654-81c9-aa4fb5e6a55c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n",
            "Epoch 1/25\n",
            "359/359 [==============================] - 78s 217ms/step - loss: 1.8014 - accuracy: 0.2553 - val_loss: 1.7573 - val_accuracy: 0.2876\n",
            "Epoch 2/25\n",
            "359/359 [==============================] - 10s 27ms/step - loss: 1.5445 - accuracy: 0.4010 - val_loss: 1.4968 - val_accuracy: 0.4268\n",
            "Epoch 3/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 1.3466 - accuracy: 0.4850 - val_loss: 1.3354 - val_accuracy: 0.4842\n",
            "Epoch 4/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 1.1978 - accuracy: 0.5453 - val_loss: 1.2370 - val_accuracy: 0.5297\n",
            "Epoch 5/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 1.0572 - accuracy: 0.6028 - val_loss: 1.2376 - val_accuracy: 0.5351\n",
            "Epoch 6/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.9022 - accuracy: 0.6669 - val_loss: 1.2445 - val_accuracy: 0.5570\n",
            "Epoch 7/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.7140 - accuracy: 0.7439 - val_loss: 1.3201 - val_accuracy: 0.5584\n",
            "Epoch 8/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.4981 - accuracy: 0.8235 - val_loss: 1.4670 - val_accuracy: 0.5624\n",
            "Epoch 9/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.3080 - accuracy: 0.8942 - val_loss: 1.9593 - val_accuracy: 0.5586\n",
            "Epoch 10/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.1898 - accuracy: 0.9398 - val_loss: 2.1591 - val_accuracy: 0.5480\n",
            "Epoch 11/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.1380 - accuracy: 0.9591 - val_loss: 2.4604 - val_accuracy: 0.5356\n",
            "Epoch 12/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0948 - accuracy: 0.9720 - val_loss: 2.6603 - val_accuracy: 0.5469\n",
            "Epoch 13/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0935 - accuracy: 0.9754 - val_loss: 2.7961 - val_accuracy: 0.5536\n",
            "Epoch 14/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0736 - accuracy: 0.9814 - val_loss: 3.0221 - val_accuracy: 0.5539\n",
            "Epoch 15/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0634 - accuracy: 0.9830 - val_loss: 3.1860 - val_accuracy: 0.5516\n",
            "Epoch 16/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0686 - accuracy: 0.9804 - val_loss: 2.9566 - val_accuracy: 0.5539\n",
            "Epoch 17/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 2.9806 - val_accuracy: 0.5462\n",
            "Epoch 18/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 3.3491 - val_accuracy: 0.5478\n",
            "Epoch 19/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0548 - accuracy: 0.9857 - val_loss: 3.5126 - val_accuracy: 0.5516\n",
            "Epoch 20/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0512 - accuracy: 0.9862 - val_loss: 3.4416 - val_accuracy: 0.5529\n",
            "Epoch 21/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 3.6181 - val_accuracy: 0.5501\n",
            "Epoch 22/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0578 - accuracy: 0.9828 - val_loss: 3.4910 - val_accuracy: 0.5522\n",
            "Epoch 23/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0436 - accuracy: 0.9893 - val_loss: 3.5439 - val_accuracy: 0.5478\n",
            "Epoch 24/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0352 - accuracy: 0.9917 - val_loss: 3.5356 - val_accuracy: 0.5501\n",
            "Epoch 25/25\n",
            "359/359 [==============================] - 10s 28ms/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 3.7507 - val_accuracy: 0.5579\n",
            "113/113 [==============================] - 41s 366ms/step - loss: 3.7482 - accuracy: 0.5541\n",
            "Test Accuracy: 55.41%\n"
          ]
        }
      ],
      "source": [
        "train_dir = r\"C:\\Users\\coder\\CNN\\train\"\n",
        "test_dir = r\"C:\\Users\\coder\\CNN\\test\"\n",
        "img_height, img_width = 48, 48\n",
        "batch_size = 64\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\",\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        ")\n",
        "with tf.device('/GPU:0'):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_height, img_width, 1)),  # CONV1\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dense(train_generator.num_classes, activation='softmax')\n",
        "    ])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "epochs = 25\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "model.save(\"fer2013_cnn_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVI6bivJ4Y30",
        "outputId": "1a8a1c24-44ee-44d5-f426-15ac86e270ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 3.7482 - accuracy: 0.5541\n",
            "Test Accuracy: 55.41%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"fer2013_cnn_model.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}